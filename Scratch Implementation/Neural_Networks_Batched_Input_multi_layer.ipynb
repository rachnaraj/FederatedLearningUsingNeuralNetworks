{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Networks_Batched_Input_multi_layer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPMR8tiZrkE3"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkSMhX8kqoID"
      },
      "source": [
        "# [Input layer with 4 Neurons] --> [Output layer with 3 neurons]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzo8-smzmX7A"
      },
      "source": [
        "### Batch Input: Multiple input examples are supplied to NN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8Ao8uxjn4p3"
      },
      "source": [
        "##### Batch size = 3; i.e., 3 input samples\n",
        "##### Input layer --> 4 neurons; each input sample is of shape (4,) vector\n",
        "##### Output layer --> 3 neurons; thus 3 weight vectors with shape (4,)\n",
        "##### Biases --> 3 biases associated with each output neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeAWm_Koml0a",
        "outputId": "6451a1dd-b1b7-41a2-cd03-5553837d0de4"
      },
      "source": [
        "\n",
        "\n",
        "inputs = [[1,2,3,2.5],\n",
        "[2.0, 5.0, 1.0, 4.0],\n",
        "[-1.5, 2.7, 3.3, 0.8]]\n",
        "\n",
        "input_matrix = np.array(inputs) # shape - (3,4); 3 input samples, each having 4 features\n",
        "\n",
        "weights = [[0.2, 0.8, 0.5, 1.0],\n",
        "\t[0.5, 0.91, 0.26, 0.5],\n",
        "\t[0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "wt_matrix = np.array(weights) # shape - (3,4); 3 sets of weights each associted with 1 output neuron, 4 weights each associated with 1 input neuron\n",
        "\n",
        "biases = [2, 3, -0.5] # (3,)\n",
        "\n",
        "# we need to take the weights.Transpose in order to multiply weights associated with each input sample\n",
        "# wt_matrix.T matrix would be of size 4X3; \n",
        "# 3 biases will get added to each row of dot product's output (shape - (3,3))\n",
        "output = np.dot(input_matrix, wt_matrix.T) + biases\n",
        "\n",
        "print (output)\n",
        "# each row represents output associated with 1 sample"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7.8    7.35   1.905]\n",
            " [10.9   10.81   2.32 ]\n",
            " [ 6.31   5.965 -0.362]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqPI1A3lqLz8"
      },
      "source": [
        "# [Input layer with 4 Neurons] --> [Hidden layer with 3 neurons] --> [Output layer with 3 Neurons]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0AQR2_vpXUT",
        "outputId": "004dc70b-20d5-4949-f70d-e1f5e676e113"
      },
      "source": [
        "# Input layer\n",
        "# layer - 1\n",
        "inputs = [[1,2,3,2.5],\n",
        "[2.0, 5.0, 1.0, 4.0],\n",
        "[-1.5, 2.7, 3.3, 0.8]]\n",
        "\n",
        "input_matrix = np.array(inputs) # shape - (3,4); 3 input samples, each having 4 features\n",
        "\n",
        "weights1 = [[0.2, 0.8, 0.5, 1.0],\n",
        "\t[0.5, 0.91, 0.26, 0.5],\n",
        "\t[0.26, -0.27, 0.17, 0.87]]\n",
        "\n",
        "wt_matrix1 = np.array(weights) # shape - (3,4); 3 sets of weights each associted with 1 output neuron, 4 weights each associated with 1 input neuron\n",
        "\n",
        "biases1 = [2, 3, -0.5] # (3,)\n",
        "\n",
        "layer1_output = np.dot(input_matrix, wt_matrix1.T) + biases1\n",
        "\n",
        "\n",
        "\n",
        "## layer - 2\n",
        "layer2_input = layer1_output # 3X3\n",
        "\n",
        "weights2 = [[0.2, 0.8, 0.5],\n",
        "\t[0.5, 0.91, 0.26],\n",
        "\t[0.26, -0.27, 0.17]]\n",
        "\n",
        "wt_matrix2 = np.array(weights2) # 3X3\n",
        "\n",
        "biases2 = [2, 3, -0.5] # (3,)\n",
        "\n",
        "layer2_output = np.dot(layer2_input, wt_matrix2.T) + biases2\n",
        "print(layer2_output)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10.3925  14.0838  -0.13265]\n",
            " [13.988   18.8903  -0.1903 ]\n",
            " [ 7.853   11.48903 -0.53149]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdcT51kmsyMg"
      },
      "source": [
        "### OOP to convert layers into individual objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ArZqHc2te1U"
      },
      "source": [
        "#### N.B: Weights are generally set in the range of [-1,1]\n",
        "* starting point for weights could be [-0.1, 0.1]\n",
        "* ##### Weights above 1, or higher weights may give rise to **Exploding Gradient** problem; wherein weights never converges\n",
        "* ##### Very small weights, give rise to **Vanishing Gradient** problem; wherein weights become so small for initial layers that there is hardly any learnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-JAtzgnt3aC"
      },
      "source": [
        "#### N.B: Feature Scaling (on input data) is required for NN. This is because gradient descent converge much faster with feature scaling than without it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIInunIN5_P7"
      },
      "source": [
        "# [Input layer with 4 Neurons] --> [Hidden layer with 5 neurons] --> [Output layer with 2 Neurons]\n",
        "* #### batch size = 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAXAmF7eseBJ",
        "outputId": "84ab9e60-361c-4458-d4ec-c742625c44a2"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "# 3 input samples\n",
        "# shape - (number of training ex, number of features/neuron)\n",
        "X = [[1, 2, 3, 4],\n",
        "     [5, 6, 7, 8],\n",
        "     [9, 10, 11, 12]]\n",
        "\n",
        "# class to add layers to our NN\n",
        "class Layer_Dense:\n",
        "    def __init__(self, cur_neurons, next_neurons):\n",
        "      # cur_neurons - Number of neurons in current layer\n",
        "      # next_neurons - Number of neurons in next layer\n",
        "      # np.random.randn - Normally distributed data points in a matrix of shape(cur_neurons, next_neurons)\n",
        "      # biases - array of zeros of shape (1,next_neurons)\n",
        "      self.weights = 0.10 * np.random.randn(next_neurons, cur_neurons)\n",
        "      self.biases = np.zeros((1, next_neurons))\n",
        "      self.output = None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = np.dot(inputs, self.weights.T) + self.biases\n",
        "\n",
        "layer1 = Layer_Dense(4,5)\n",
        "layer2 = Layer_Dense(5,2)\n",
        "\n",
        "layer1.forward(X) # input matrix will be the input to first layer\n",
        "\n",
        "#print(layer1.output)\n",
        "layer2.forward(layer1.output) # output of first layer will be the input to next layer\n",
        "\n",
        "print(layer2.output)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.35380693 -0.18662673]\n",
            " [-0.77493552 -0.36525802]\n",
            " [-1.19606411 -0.5438893 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aOYAn2z7MqU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}