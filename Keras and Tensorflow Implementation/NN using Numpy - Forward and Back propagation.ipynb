{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN using Numpy - Forward and Back propagation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNkNIAr8Gh0i2HSQwtqSx+5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"o4DDM3LeVpiZ"},"source":["#### [Article on NN from Scratch](https://www.analyticsvidhya.com/blog/2020/07/neural-networks-from-scratch-in-python-and-r/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pL-ZvvouVdux","executionInfo":{"status":"ok","timestamp":1632234939633,"user_tz":-330,"elapsed":952,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}},"outputId":"89e81d00-dd99-4065-f7ec-b89b747716f6"},"source":["# importing the library\n","import numpy as np\n","\n","# creating the input array\n","# batch size - 3; number of features - 4\n","X=np.array([[1,0,1,0],\n","            [1,0,1,1],\n","            [0,1,0,1]])\n","\n","print ('\\n Input:')\n","print(X)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Input:\n","[[1 0 1 0]\n"," [1 0 1 1]\n"," [0 1 0 1]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VS_Ff5F3V7sp","executionInfo":{"status":"ok","timestamp":1632234939634,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}},"outputId":"d3591c93-6397-4c17-8eb2-1f059fa0ea55"},"source":["# creating the output array\n","# output corresponding to each input sample\n","\n","y=np.array([[1],\n","            [1],\n","            [0]])\n","\n","print ('\\n Actual Output:')\n","print(y)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Actual Output:\n","[[1]\n"," [1]\n"," [0]]\n"]}]},{"cell_type":"code","metadata":{"id":"Ep8FUoHccDQD","executionInfo":{"status":"ok","timestamp":1632234939635,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}}},"source":["# defining the Sigmoid Function\n","def sigmoid (x):\n","    return 1/(1 + np.exp(-x))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fo1B6LSMb9Oj"},"source":["#### [Calculating derivative of sigmoid function](https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e)"]},{"cell_type":"code","metadata":{"id":"M4Qqd8mYcEur","executionInfo":{"status":"ok","timestamp":1632234939635,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}}},"source":["# derivative of Sigmoid Function\n","def derivatives_sigmoid(x):\n","    return x * (1 - x)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMUbPfYtcyoF","executionInfo":{"status":"ok","timestamp":1632234939636,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}}},"source":["# initializing the variables\n","epoch=5000 # number of training iterations\n","lr = 0.1 # learning rate\n","inputlayer_neurons = X.shape[1] # number of features in data set\n","hiddenlayer_neurons = 3 # number of hidden layers neurons\n","output_neurons = 1 # number of neurons at output layer"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9L9Iq7_nefHM","executionInfo":{"status":"ok","timestamp":1632234939636,"user_tz":-330,"elapsed":7,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}}},"source":["# initializing weight and bias\n","weight_h = np.random.uniform(size = (hiddenlayer_neurons, inputlayer_neurons)) # (number of neurons in hidden layer,  number of neurons in input layer)\n","bias_h = np.random.uniform(size = (1,hiddenlayer_neurons)) # (1, number of neurons in hidden layer)\n","weight_out = np.random.uniform(size = (output_neurons, hiddenlayer_neurons)) # (1, number of neurons in hidden layer)\n","bias_out = np.random.uniform(size = (1,output_neurons)) "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjQ9XrF1jAgw"},"source":["#### [Back Propagation Calculation](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)\n","#### [Back propagation whole code](https://github.com/mattm/simple-neural-network)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8f_pv-BXe3V","executionInfo":{"status":"ok","timestamp":1632234964961,"user_tz":-330,"elapsed":595,"user":{"displayName":"Anirban Sarkar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0nkBNcBoBH15E3mv4EXPGw-1iwV4bHtX6TOBQ7cE=s64","userId":"09228385914535842530"}},"outputId":"311c1c98-90e3-4ea8-edee-d027f6738f34"},"source":["# training the model\n","for i in range(epoch):\n","\n","    ### Forward Propogation\n","    hidden_layer_input = np.dot(X, weight_h.T) + bias_h # output_shape --> (number of training samples, number of hidden neurons); bias value will be added to row\n","    hiddenlayer_activations = sigmoid(hidden_layer_input) # sigmoid of each value in input matrix\n","    \n","    output_layer_input = np.dot(hiddenlayer_activations, weight_out.T) + bias_out # output_shape --> (number of training samples, 1)\n","\n","    output_activations = sigmoid(output_layer_input) # shape - (number of input samples, 1)\n","\n","\n","\n","    ### Backpropagation\n","    Error = y - output_activations # derivative of error wrt output; shape -- (number of input samples, 1)\n","\n","    slope_output_layer = derivatives_sigmoid(output_activations) # derivative on final output; shape - (number of input samples, 1)\n","    delta_output = Error * slope_output_layer # calculating delta output; \"row wise multiplication\"; shape --(number of input samples, 1)\n","\n","    slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations) # derivative of output from hidden layer; shape -- (number of training samples, number of hidden neurons)  \n","    Error_at_hidden_layer = delta_output.dot(weight_out) # shape -- (number of training samples, number of neurons in hidden layer) \n","    \n","    delta_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer # element wise multiplication; shape -- # shape -- (number of training samples, number of neurons in hidden layer)\n","    \n","    # weight & bias updation\n","    weight_out += delta_output.T.dot(hiddenlayer_activations.T) * lr # shape -- (1, number of neurons in hidden layer)\n","    bias_out += np.sum(delta_output, axis=0, keepdims=True) * lr # shape -- (1, 1)\n","    weight_h += delta_hiddenlayer.T.dot(X) *  lr # (number of neurons in hidden layer,  number of neurons in input layer) \n","    bias_h += np.sum(delta_hiddenlayer, axis=0,keepdims=True) *lr # (1, number of neurons in hidden layer)\n","\n","print ('\\n Output from the model:')\n","print (output_activations)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Output from the model:\n","[[0.97827167]\n"," [0.97459246]\n"," [0.03085085]]\n"]}]},{"cell_type":"code","metadata":{"id":"juB5vO6syQIP"},"source":[""],"execution_count":null,"outputs":[]}]}